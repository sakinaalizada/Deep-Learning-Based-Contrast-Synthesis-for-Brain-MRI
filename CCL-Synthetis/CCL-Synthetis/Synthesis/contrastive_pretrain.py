"""
Pretraining Script for MR-Contrast Guided Contrastive Learning (CCL)
Author: Sakina (reconstructed)
Purpose: Pretrain encoder using anatomical constraint‚Äìguided contrastive learning
Output: pretrained weights (e.g., weights_150.hdf5)
"""

import os
import sys
import tensorflow as tf
import numpy as np
import pathlib
import logging

# -------------------------------------------------------------------------
# Setup
# -------------------------------------------------------------------------
sys.path.append(os.path.expanduser('~/CCL-Synthetis/'))

from Synthesis import synth_config as cfg
from utils.utils import get_callbacks
from utils.model_utils import modelObj
from utils.constrained_contrastive_loss import lossObj as CCLLoss
from Datagen.h5_pretrain_Synth_Data_Generator import DataLoaderObj

# ----------------------------- GPU setup ----------------------------- #
os.environ['CUDA_VISIBLE_DEVICES'] = cfg.gpus_available
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'
logging.getLogger('tensorflow').setLevel(logging.FATAL)

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
print("‚úÖ GPUs available:", len(gpus))

# -------------------------------------------------------------------------
# Load Data
# -------------------------------------------------------------------------
print("üìÇ Loading pretraining data from HDF5 files...")

# These HDF5 paths should come from cfg (generated by the pretraining data generator)
train_gen = DataLoaderObj(cfg, train_flag=True)
val_gen   = DataLoaderObj(cfg, train_flag=False)

print(f"Training samples: {len(train_gen)}, Validation samples: {len(val_gen)}")

# -------------------------------------------------------------------------
# Model Setup
# -------------------------------------------------------------------------
print("üß† Building encoder model for pretraining...")
model = modelObj(cfg)
encoder_model = model.encoder_network(add_PH=True)

# -------------------------------------------------------------------------
# Loss and Optimizer
# -------------------------------------------------------------------------
print("‚öôÔ∏è Setting up loss and optimizer...")
loss_fn = CCLLoss(cfg).calc_CCL_batchwise  # main constrained contrastive loss
optimizer = tf.keras.optimizers.Adam(learning_rate=cfg.lr_pretrain)

encoder_model.compile(optimizer=optimizer, loss=loss_fn)
print("‚úÖ Model compiled with constrained contrastive loss")

# -------------------------------------------------------------------------
# Output / Callbacks
# -------------------------------------------------------------------------
save_dir = os.path.join(cfg.save_dir, f'CCL_Pretrain_{cfg.datatype}')
pathlib.Path(save_dir).mkdir(parents=True, exist_ok=True)

weights_path = os.path.join(save_dir, 'weights_{epoch:03d}.hdf5')
csv_log_path = os.path.join(save_dir, 'training.log')

callbacks = get_callbacks(csv_log_path)

# -------------------------------------------------------------------------
# Training
# -------------------------------------------------------------------------
print("üöÄ Starting CCL Pretraining...")
history = encoder_model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=cfg.num_epochs_pretrain,
    callbacks=callbacks,
    verbose=1
)

# -------------------------------------------------------------------------
# Save final weights and config
# -------------------------------------------------------------------------
final_wts = os.path.join(save_dir, f'weights_{cfg.num_epochs_pretrain}_final.hdf5')
encoder_model.save_weights(final_wts)
print(f"‚úÖ Pretraining complete. Final weights saved to {final_wts}")

cfg_txt_name = os.path.join(save_dir, 'config_params.txt')
with open(cfg_txt_name, 'w') as f:
    for name, value in cfg.__dict__.items():
        f.write(f'{name} = {value!r}\n')
print(f"üìù Config saved to {cfg_txt_name}")
